'use client';

import { useEffect, useRef, useState, useCallback } from 'react';

export function useVoice({ threshold = 15 } = {}) {
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isActive, setIsActive] = useState(false);

  const streamRef = useRef(null);
  const audioContextRef = useRef(null);
  const analyserRef = useRef(null);
  const dataArrayRef = useRef(null);
  const intervalRef = useRef(null);

  const mediaRecorderRef = useRef(null);
  const chunksRef = useRef([]);

  // üîä –¢–æ–ª—å–∫–æ –∞–Ω–∞–ª–∏–∑ —Ä–µ—á–∏ (–±–µ–∑ –∑–∞–ø–∏—Å–∏)
  const startListening = useCallback(async () => {
    if (isActive) return;

    try {
      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
      streamRef.current = stream;

      const audioContext = new AudioContext();
      const analyser = audioContext.createAnalyser();
      analyser.fftSize = 512;

      const mic = audioContext.createMediaStreamSource(stream);
      mic.connect(analyser);

      const dataArray = new Uint8Array(analyser.fftSize);

      audioContextRef.current = audioContext;
      analyserRef.current = analyser;
      dataArrayRef.current = dataArray;

      intervalRef.current = setInterval(() => {
        analyser.getByteTimeDomainData(dataArray);
        const isNowSpeaking = dataArray.some(v => Math.abs(v - 128) > threshold);
        setIsSpeaking(isNowSpeaking);
      }, 200);

      setIsActive(true);
    } catch (err) {
      console.error('–û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É', err);
    }
  }, [threshold, isActive]);

  // ‚è∫Ô∏è –û—Ç–¥–µ–ª—å–Ω–æ –Ω–∞—á–∞—Ç—å –∑–∞–ø–∏—Å—å (–µ—Å–ª–∏ —Å—Ç—Ä–∏–º —É–∂–µ –µ—Å—Ç—å)
  const startRecording = useCallback(() => {
    if (!streamRef.current) {
      console.warn('–ù–µ—Ç –∞–∫—Ç–∏–≤–Ω–æ–≥–æ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –¥–ª—è –∑–∞–ø–∏—Å–∏');
      return;
    }

    try {
      const mediaRecorder = new MediaRecorder(streamRef.current);
      chunksRef.current = [];

      mediaRecorder.ondataavailable = e => {
        if (e.data.size > 0) {
          chunksRef.current.push(e.data);
        }
      };

      mediaRecorder.start();
      mediaRecorderRef.current = mediaRecorder;
    } catch (err) {
      console.error('–û—à–∏–±–∫–∞ –∑–∞–ø—É—Å–∫–∞ –∑–∞–ø–∏—Å–∏:', err);
    }
  }, []);

  // ‚èπÔ∏è –û—Å—Ç–∞–Ω–æ–≤–∏—Ç—å —Ç–æ–ª—å–∫–æ –∑–∞–ø–∏—Å—å –∏ –≤–µ—Ä–Ω—É—Ç—å blob
  const stopRecording = useCallback(() => {
    return new Promise(resolve => {
      if (!mediaRecorderRef.current) return resolve(null);

      const recorder = mediaRecorderRef.current;

      recorder.onstop = () => {
        const blob = new Blob(chunksRef.current, { type: 'audio/webm' });
        chunksRef.current = [];
        resolve(blob);
      };

      if (recorder.state === 'recording') {
        recorder.stop();
      } else {
        resolve(null);
      }
    });
  }, []);

  // üõë –ü–æ–ª–Ω–∞—è –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ + –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
  const stopListening = useCallback(() => {
    if (!isActive) return;

    if (intervalRef.current) clearInterval(intervalRef.current);
    if (audioContextRef.current) audioContextRef.current.close();
    if (streamRef.current) {
      streamRef.current.getTracks().forEach(track => track.stop());
    }

    intervalRef.current = null;
    audioContextRef.current = null;
    streamRef.current = null;
    analyserRef.current = null;
    dataArrayRef.current = null;
    setIsSpeaking(false);
    setIsActive(false);
  }, [isActive]);

  useEffect(() => {
    return () => {
      stopListening();
    };
  }, [stopListening]);

  return {
    isSpeaking,
    isActive,
    startListening, // —Ç–æ–ª—å–∫–æ –∞–Ω–∞–ª–∏–∑ —Ä–µ—á–∏
    stopListening, // –æ—Å—Ç–∞–Ω–æ–≤–∫–∞ –≤—Å–µ–≥–æ
    startRecording, // –≤–∫–ª—é—á–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏ (–ø—Ä–∏ active –º–∏–∫—Ä–æ—Ñ–æ–Ω–µ)
    stopRecording, // –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –∏ –ø–æ–ª—É—á–µ–Ω–∏–µ blob
  };
}
